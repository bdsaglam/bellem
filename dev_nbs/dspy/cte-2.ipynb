{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import dspy\n",
    "from dspy.primitives.program import Module\n",
    "from dspy.signatures.signature import ensure_signature\n",
    "\n",
    "\n",
    "def validate_triples_format(triples: str, sep: str = \";\") -> bool:\n",
    "    \"\"\"Check if the triples are in the correct format.\"\"\"\n",
    "    return any(len(triple.split(sep)) != 3 for triple in triples.splitlines())\n",
    "\n",
    "_prefix = \"\"\"\n",
    "Let's identify the relevant entity-relation-entity triples in the format of 'subj;relation;obj'. For example,\n",
    "London;capital of;United Kingdom\n",
    "Barrack Obama;birth place;Hawaii\n",
    "\"\"\".strip()\n",
    "\n",
    "class ConnectTheEntities(Module):\n",
    "    def __init__(self, signature, rationale_type=None, activated=True, **config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activated = activated\n",
    "\n",
    "        self.signature = signature = ensure_signature(signature)\n",
    "\n",
    "        desc = \"${triples}\"\n",
    "        rationale_type = rationale_type or dspy.OutputField(prefix=_prefix, desc=desc)\n",
    "\n",
    "        # Add \"triples\" field to the output signature.\n",
    "        extended_signature = signature.prepend(\"triples\", rationale_type, type_=str)\n",
    "\n",
    "        self._predict = dspy.Predict(extended_signature, **config)\n",
    "        self._predict.extended_signature = extended_signature\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        assert self.activated in [True, False]\n",
    "\n",
    "        signature = kwargs.pop(\"new_signature\", self._predict.extended_signature if self.activated else self.signature)\n",
    "        pred = self._predict(signature=signature, **kwargs)\n",
    "        dspy.Suggest(\n",
    "            validate_triples_format(pred.triples),\n",
    "            \"Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.\",\n",
    "            target_module=self._predict,\n",
    "        )\n",
    "        return pred\n",
    "\n",
    "    @property\n",
    "    def demos(self):\n",
    "        return self._predict.demos\n",
    "\n",
    "    @property\n",
    "    def extended_signature(self):\n",
    "        return self._predict.extended_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import typer\n",
    "from pathlib import Path\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from datasets import load_dataset\n",
    "from bellek.utils import set_seed\n",
    "from bellek.musique.eval import (\n",
    "    aggregate_scores,\n",
    "    compute_scores,\n",
    "    compute_scores_dataframe,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "from rich.console import Console\n",
    "\n",
    "print = Console(stderr=True).print\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "set_seed(89)\n",
    "\n",
    "\n",
    "def configure_lm(model, temperature):\n",
    "    lm = dspy.LM(\n",
    "        \"openai/\" + model,\n",
    "        temperature=temperature,\n",
    "        cache=False,\n",
    "        api_base=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "    dspy.configure(lm=lm)\n",
    "\n",
    "\n",
    "def format_paragraph(paragraph):\n",
    "    text = paragraph[\"paragraph_text\"]\n",
    "    title = paragraph[\"title\"]\n",
    "    return f\"# {title}\\n{text}\"\n",
    "\n",
    "\n",
    "def make_example(record):\n",
    "    supporting_paragraphs = [p for p in record[\"paragraphs\"] if p[\"is_supporting\"]]\n",
    "    context = \"\\n\\n\".join([format_paragraph(p) for p in supporting_paragraphs])\n",
    "    return dspy.Example(\n",
    "        id=record[\"id\"],\n",
    "        question=record[\"question\"],\n",
    "        question_decomposition=record[\"question_decomposition\"],\n",
    "        context=context,\n",
    "        answer=record[\"answer\"],\n",
    "        answers=[record[\"answer\"], *record[\"answer_aliases\"]],\n",
    "    ).with_inputs(\"question\", \"context\")\n",
    "\n",
    "\n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer the question based on the given context.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "\n",
    "class QAModule(dspy.Module):\n",
    "    def __init__(self, predict_cls=dspy.Predict):\n",
    "        super().__init__()\n",
    "        self.generate_answer = predict_cls(GenerateAnswer)\n",
    "\n",
    "    def forward(self, context, question):\n",
    "        return self.generate_answer(context=context, question=question)\n",
    "\n",
    "\n",
    "def get_predict_cls(technique):\n",
    "    if technique == \"standard\":\n",
    "        return dspy.Predict\n",
    "    elif technique == \"cot\":\n",
    "        return dspy.ChainOfThought\n",
    "    elif technique == \"cte\":\n",
    "\n",
    "        return ConnectTheEntities\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown technique: {technique}\")\n",
    "\n",
    "\n",
    "def evaluate_answer(example, pred, trace=None):\n",
    "    scores = compute_scores(pred.answer, example.answers)\n",
    "    return scores[\"f1\"]\n",
    "\n",
    "\n",
    "def dynamic_import(module, name):\n",
    "    import importlib\n",
    "\n",
    "    return getattr(importlib.import_module(module), name)\n",
    "\n",
    "\n",
    "def make_optimizer(optimizer_config: dict):\n",
    "    cls = dynamic_import(\"dspy.teleprompt\", optimizer_config[\"class\"])\n",
    "    kwargs = deepcopy(optimizer_config[\"params\"])\n",
    "    if optimizer_config[\"with_metric\"]:\n",
    "        kwargs[\"metric\"] = evaluate_answer\n",
    "    return cls(**kwargs)\n",
    "\n",
    "\n",
    "def preprocess_result(result):\n",
    "    example, pred, score = result\n",
    "    predictions = {f\"predicted_{k}\": v for k, v in dict(pred).items()}\n",
    "    return {**dict(example), **predictions, \"score\": float(score)}\n",
    "\n",
    "\n",
    "def make_results_dataframe(results):\n",
    "    dataf = pd.json_normalize([preprocess_result(result) for result in results])\n",
    "    dataf[\"n_hops\"] = dataf[\"question_decomposition\"].apply(len)\n",
    "    dataf['predicted_answer'] = dataf['predicted_answer'].fillna(\"No Answer\")\n",
    "    return compute_scores_dataframe(dataf)\n",
    "\n",
    "\n",
    "def train_main(\n",
    "    dataset_path: str = typer.Option(..., help=\"Path to the dataset\"),\n",
    "    dataset_name: str = typer.Option(..., help=\"Name of the dataset\"),\n",
    "    dataset_split: str = typer.Option(..., help=\"Dataset split to use (e.g., 'train', 'validation')\"),\n",
    "    model: str = typer.Option(..., help=\"Name of the model to use\"),\n",
    "    temperature: float = typer.Option(..., help=\"Temperature parameter for the model\"),\n",
    "    technique: str = typer.Option(..., help=\"Prompting technique to use\"),\n",
    "    load_from: str = typer.Option(default=\"UNSET\", help=\"Path to a saved model to load\"),\n",
    "    optimizer_path: Path = typer.Option(..., help=\"Path to the optimizer config\"),\n",
    "):\n",
    "    # Set up LLM\n",
    "    configure_lm(model, temperature)\n",
    "\n",
    "    # Load and preprocess datasets\n",
    "    ds = load_dataset(dataset_path, dataset_name, split=dataset_split)\n",
    "    examples = [make_example(record) for record in ds]\n",
    "    print(f\"Loaded {len(examples)} examples\")\n",
    "\n",
    "    # Create the program\n",
    "    program = QAModule(predict_cls=get_predict_cls(technique))\n",
    "    if load_from and load_from != \"UNSET\":\n",
    "        print(f\"Loading model from {load_from}\")\n",
    "        program.load(load_from)\n",
    "\n",
    "    # Train the program\n",
    "    with open(optimizer_path) as f:\n",
    "        optimizer_config = json.load(f)\n",
    "\n",
    "    if optimizer_config:\n",
    "        optimizer = make_optimizer(optimizer_config)\n",
    "        compile_params = optimizer_config.get(\"compile_params\", {})\n",
    "        trained_program = optimizer.compile(program, trainset=examples, **compile_params)\n",
    "    else:\n",
    "        trained_program = program\n",
    "\n",
    "    # Save the trained program\n",
    "    return trained_program\n",
    "\n",
    "\n",
    "def evaluate_main(\n",
    "    dataset_path: str = typer.Option(..., help=\"Path to the dataset\"),\n",
    "    dataset_name: str = typer.Option(..., help=\"Name of the dataset\"),\n",
    "    dataset_split: str = typer.Option(..., help=\"Dataset split to use (e.g., 'train', 'validation')\"),\n",
    "    model: str = typer.Option(..., help=\"Name of the model to use\"),\n",
    "    temperature: float = typer.Option(..., help=\"Temperature parameter for the model\"),\n",
    "    technique: str = typer.Option(..., help=\"Prompting technique to use\"),\n",
    "    program = None,\n",
    "):\n",
    "    # Set up LLM\n",
    "    configure_lm(model, temperature)\n",
    "\n",
    "    # Load and preprocess datasets\n",
    "    ds = load_dataset(dataset_path, dataset_name, split=dataset_split)\n",
    "    examples = [make_example(record) for record in ds]\n",
    "    print(f\"Loaded {len(examples)} examples\")\n",
    "\n",
    "    # Create the program\n",
    "    if program is None:\n",
    "        program = QAModule(predict_cls=get_predict_cls(technique))\n",
    "\n",
    "    # Evaluate the program\n",
    "    evaluate_program = Evaluate(\n",
    "        metric=evaluate_answer,\n",
    "        devset=examples,\n",
    "        num_threads=16,\n",
    "        display_progress=True,\n",
    "        return_outputs=True,\n",
    "    )\n",
    "    _, results = evaluate_program(program)\n",
    "\n",
    "    # Save the results\n",
    "    result_df = make_results_dataframe(results)\n",
    "\n",
    "    # Save the scores\n",
    "    scores = aggregate_scores(result_df)\n",
    "    for n_hops in result_df[\"n_hops\"].unique():\n",
    "        scores[f\"{n_hops}hops\"] = aggregate_scores(result_df[result_df[\"n_hops\"] == n_hops])\n",
    "\n",
    "\n",
    "    return result_df, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loaded \u001b[1;36m300\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 4 traces per predictor.\n",
      "Will attempt to bootstrap 16 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.933333333333334 / 23  (86.7):   8%|▊         | 23/300 [00:13<02:06,  2.19it/s]\u001b[2m2024-10-26T07:47:13.834872Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.. Set `provide_traceback=True` to see the stack trace.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m200\u001b[0m\n",
      "Average Metric: 19.933333333333334 / 25  (79.7):   8%|▊         | 24/300 [00:15<02:57,  1.56it/s]\u001b[2m2024-10-26T07:47:13.966459Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.. Set `provide_traceback=True` to see the stack trace.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m200\u001b[0m\n",
      "Average Metric: 93.99737274220033 / 116  (81.0):  38%|███▊      | 115/300 [00:54<01:22,  2.23it/s]\u001b[2m2024-10-26T07:47:54.392726Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.. Set `provide_traceback=True` to see the stack trace.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m200\u001b[0m\n",
      "Average Metric: 115.37865616466024 / 148  (78.0):  49%|████▉     | 148/300 [01:10<01:15,  2.02it/s]\u001b[2m2024-10-26T07:48:10.219966Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.. Set `provide_traceback=True` to see the stack trace.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m200\u001b[0m\n",
      "Average Metric: 129.87865616466024 / 171  (76.0):  57%|█████▋    | 170/300 [01:22<00:46,  2.81it/s]\u001b[2m2024-10-26T07:48:21.349052Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.. Set `provide_traceback=True` to see the stack trace.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m200\u001b[0m\n",
      "Average Metric: 131.27865616466025 / 174  (75.4):  58%|█████▊    | 174/300 [01:24<01:07,  1.86it/s]\u001b[2m2024-10-26T07:48:23.311539Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.. Set `provide_traceback=True` to see the stack trace.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m200\u001b[0m\n",
      "Average Metric: 140.64532283132692 / 187  (75.2):  62%|██████▏   | 186/300 [01:30<01:12,  1.56it/s]\u001b[2m2024-10-26T07:48:29.364587Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.. Set `provide_traceback=True` to see the stack trace.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m200\u001b[0m\n",
      "Average Metric: 166.50643394243804 / 225  (74.0):  75%|███████▌  | 225/300 [01:52<00:42,  1.76it/s]\u001b[2m2024-10-26T07:48:52.433855Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.. Set `provide_traceback=True` to see the stack trace.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m200\u001b[0m\n",
      "Average Metric: 185.7231006091047 / 252  (73.7):  84%|████████▍ | 252/300 [02:09<00:30,  1.58it/s] \u001b[2m2024-10-26T07:49:09.272535Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.. Set `provide_traceback=True` to see the stack trace.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m200\u001b[0m\n",
      "Average Metric: 187.2231006091047 / 255  (73.4):  85%|████████▌ | 255/300 [02:11<00:28,  1.55it/s]"
     ]
    },
    {
     "ename": "DSPySuggestionError",
     "evalue": "Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDSPySuggestionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_program \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_main\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbdsaglam/musique-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswerable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama-3-70b-tgi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtechnique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcte\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbfsrs-medium.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUNSET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 149\u001b[0m, in \u001b[0;36mtrain_main\u001b[0;34m(dataset_path, dataset_name, dataset_split, model, temperature, technique, load_from, optimizer_path)\u001b[0m\n\u001b[1;32m    147\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m make_optimizer(optimizer_config)\n\u001b[1;32m    148\u001b[0m     compile_params \u001b[38;5;241m=\u001b[39m optimizer_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_params\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m--> 149\u001b[0m     trained_program \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompile_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     trained_program \u001b[38;5;241m=\u001b[39m program\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/dspy/teleprompt/random_search.py:119\u001b[0m, in \u001b[0;36mBootstrapFewShotWithRandomSearch.compile\u001b[0;34m(self, student, teacher, trainset, valset, restrict, labeled_sample)\u001b[0m\n\u001b[1;32m    108\u001b[0m     program \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mcompile(student, teacher\u001b[38;5;241m=\u001b[39mteacher, trainset\u001b[38;5;241m=\u001b[39mtrainset_copy)\n\u001b[1;32m    110\u001b[0m evaluate \u001b[38;5;241m=\u001b[39m Evaluate(\n\u001b[1;32m    111\u001b[0m     devset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalset,\n\u001b[1;32m    112\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m     display_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m )\n\u001b[0;32m--> 119\u001b[0m score, subscores \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_all_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m all_subscores\u001b[38;5;241m.\u001b[39mappend(subscores)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m############ Assertion-aware Optimization ############\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:215\u001b[0m, in \u001b[0;36mEvaluate.__call__\u001b[0;34m(self, program, metric, devset, num_threads, display_progress, display_table, return_all_scores, return_outputs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_single_thread(wrapped_program, devset, display_progress)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_multi_thread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapped_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m dspy\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mncorrect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mntotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mncorrect\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mntotal,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    224\u001b[0m predicted_devset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(reordered_devset)\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:124\u001b[0m, in \u001b[0;36mEvaluate._execute_multi_thread\u001b[0;34m(self, wrapped_program, devset, num_threads, display_progress)\u001b[0m\n\u001b[1;32m    121\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(devset), dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m display_progress)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[0;32m--> 124\u001b[0m     example_idx, example, prediction, score \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# use the cancelled_job literal to check if the job was cancelled - use \"is\" not \"==\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# in case the prediction is \"cancelled\" for some reason.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;129;01mis\u001b[39;00m job_cancelled:\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:117\u001b[0m, in \u001b[0;36mEvaluate._execute_multi_thread.<locals>.cancellable_wrapped_program\u001b[0;34m(idx, arg)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_jobs\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, job_cancelled, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_program\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:193\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[0;34m(example_idx, example)\u001b[0m\n\u001b[1;32m    191\u001b[0m     current_error_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_count\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_error_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_errors:\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprovide_traceback:\n\u001b[1;32m    196\u001b[0m     dspy\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError for example in dev set: \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mwith inputs:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;241m.\u001b[39minputs()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStack trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:175\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[0;34m(example_idx, example)\u001b[0m\n\u001b[1;32m    172\u001b[0m     thread_stacks[threading\u001b[38;5;241m.\u001b[39mget_ident()] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dspy\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mmain_stack)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     score \u001b[38;5;241m=\u001b[39m metric(\n\u001b[1;32m    177\u001b[0m         example,\n\u001b[1;32m    178\u001b[0m         prediction,\n\u001b[1;32m    179\u001b[0m     )  \u001b[38;5;66;03m# FIXME: TODO: What's the right order? Maybe force name-based kwargs!\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# increment assert and suggest failures to program's attributes\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/dspy/primitives/program.py:20\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 71\u001b[0m, in \u001b[0;36mQAModule.forward\u001b[0;34m(self, context, question)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, context, question):\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/dspy/primitives/program.py:20\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 39\u001b[0m, in \u001b[0;36mConnectTheEntities.forward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m signature \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict\u001b[38;5;241m.\u001b[39mextended_signature \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivated \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature)\n\u001b[1;32m     38\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(signature\u001b[38;5;241m=\u001b[39msignature, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mdspy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSuggest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_triples_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTriples must be in the format of \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubj;relation;obj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m and each triple must be in a new line.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/dspy/primitives/assertions.py:74\u001b[0m, in \u001b[0;36mConstraint.__init__\u001b[0;34m(self, result, msg, target_module, is_metric)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_module \u001b[38;5;241m=\u001b[39m target_module\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_metric \u001b[38;5;241m=\u001b[39m is_metric\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/dspy/primitives/assertions.py:112\u001b[0m, in \u001b[0;36mSuggest.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m         dspy\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuggestionFailed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DSPySuggestionError(\n\u001b[1;32m    113\u001b[0m             \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    114\u001b[0m             msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsg,\n\u001b[1;32m    115\u001b[0m             target_module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_module,\n\u001b[1;32m    116\u001b[0m             state\u001b[38;5;241m=\u001b[39mdsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mtrace,\n\u001b[1;32m    117\u001b[0m             is_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_metric,\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuggestion function should always return [bool]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mDSPySuggestionError\u001b[0m: Triples must be in the format of 'subj;relation;obj' and each triple must be in a new line."
     ]
    }
   ],
   "source": [
    "trained_program = train_main(\n",
    "    dataset_path=\"bdsaglam/musique-mini\",\n",
    "    dataset_name=\"answerable\",\n",
    "    dataset_split=\"train\",\n",
    "    model=\"llama-3-70b-tgi\",\n",
    "    temperature=0.1,\n",
    "    technique=\"cte\",\n",
    "    optimizer_path=Path(\"bfsrs-medium.json\"),\n",
    "    load_from=\"UNSET\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loaded \u001b[1;36m300\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    triples='Centerpoint Medical Center is located in Missouri. Missouri has a mean temperature of 24 ° C (75 ° F) in the summer.',\n",
       "    answer='75 ° F'\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path=\"bdsaglam/musique-mini\"\n",
    "dataset_name=\"answerable\"\n",
    "dataset_split=\"train\"\n",
    "model=\"llama-3-70b-tgi\"\n",
    "temperature=0.1\n",
    "technique=\"cte\"\n",
    "optimizer_path=Path(\"bfsrs-medium.json\")\n",
    "load_from=\"UNSET\"\n",
    "\n",
    "# Set up LLM\n",
    "configure_lm(model, temperature)\n",
    "\n",
    "# Load and preprocess datasets\n",
    "ds = load_dataset(dataset_path, dataset_name, split=dataset_split)\n",
    "examples = [make_example(record) for record in ds]\n",
    "print(f\"Loaded {len(examples)} examples\")\n",
    "\n",
    "# Create the program\n",
    "program = QAModule(predict_cls=ConnectTheEntities)\n",
    "\n",
    "# Train the program\n",
    "# optimizer_config = json.load(optimizer_path.open())\n",
    "# optimizer = make_optimizer(optimizer_config)\n",
    "# compile_params = optimizer_config.get(\"compile_params\", {})\n",
    "# trained_program = optimizer.compile(program, trainset=examples, **compile_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># Climate of Missouri\n",
       "Summer, June through August, is the hottest time of the year with a mean temperature of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> ° C <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span> ° F<span style=\"font-weight: bold\">)</span> and a mean \n",
       "precipitation of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span> mm <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> inches<span style=\"font-weight: bold\">)</span> with June having more precipitation than either July or August. The extreme \n",
       "highs for the year often occur in July or August. Tropical cyclones and their remains can impact the state during \n",
       "this time of the year, contributing to area rainfall.\n",
       "\n",
       "# Centerpoint Medical Center\n",
       "Centerpoint Medical Center is a hospital located in Independence, Missouri at <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19600</span> East 39th Street. It is part of\n",
       "the HCA Midwest Division.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# Climate of Missouri\n",
       "Summer, June through August, is the hottest time of the year with a mean temperature of \u001b[1;36m24\u001b[0m ° C \u001b[1m(\u001b[0m\u001b[1;36m75\u001b[0m ° F\u001b[1m)\u001b[0m and a mean \n",
       "precipitation of \u001b[1;36m300\u001b[0m mm \u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m inches\u001b[1m)\u001b[0m with June having more precipitation than either July or August. The extreme \n",
       "highs for the year often occur in July or August. Tropical cyclones and their remains can impact the state during \n",
       "this time of the year, contributing to area rainfall.\n",
       "\n",
       "# Centerpoint Medical Center\n",
       "Centerpoint Medical Center is a hospital located in Independence, Missouri at \u001b[1;36m19600\u001b[0m East 39th Street. It is part of\n",
       "the HCA Midwest Division.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is the average summer temperature in the state which holds Centerpoint Medical Center?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "What is the average summer temperature in the state which holds Centerpoint Medical Center?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    triples='Centerpoint Medical Center is located in Missouri. Missouri has a mean temperature of 24 ° C (75 ° F) in the summer.',\n",
       "    answer='75 ° F'\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = examples[0]\n",
    "print(example.context)\n",
    "print(example.question)\n",
    "pred = program.forward(context=example.context, question=example.question)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
