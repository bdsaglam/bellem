{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bellem.utils import set_seed\n",
    "import numpy as np\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "set_seed(89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-hop variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_nhop_variant(path: str, config_name: str, n_hop: int):\n",
    "    dsd = load_dataset(path, config_name)\n",
    "    target_dsd = DatasetDict()\n",
    "    for split, ds in dsd.items():\n",
    "        target_dsd[split] = ds.filter(lambda example: len(example['question_decomposition']) == n_hop)\n",
    "    target_dsd.push_to_hub(f\"{path}-{n_hop}hop\", config_name=config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish_nhop_variant(\"bdsaglam/musique\", \"default\", 2)\n",
    "# publish_nhop_variant(\"bdsaglam/musique\", \"answerable\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini version with equal distribution of number of hops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that samples from the dataset with equal distribution of n_hops\n",
    "def sample_evenly(dataset, n_samples):\n",
    "    dataset = dataset.map(lambda x: {'n_hops': len(x['question_decomposition'])})\n",
    "    n_hops = np.unique(dataset['n_hops'])\n",
    "    samples_per_hop = n_samples // len(n_hops)\n",
    "    for hop in n_hops:\n",
    "        hop_samples = dataset.filter(lambda x: x['n_hops'] == hop).shuffle().select(range(samples_per_hop))\n",
    "        yield from hop_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_mini_variant(path: str, config_name: str, n_samples: int):\n",
    "    dsd = load_dataset(path, config_name)\n",
    "    target_dsd = DatasetDict()\n",
    "    for split, ds in dsd.items():\n",
    "        target_dsd[split] = Dataset.from_list(list(sample_evenly(ds, n_samples)))\n",
    "    target_dsd.push_to_hub(f\"{path}-mini\", config_name=config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish_mini_variant(\"bdsaglam/musique\", \"default\", 300)\n",
    "# publish_mini_variant(\"bdsaglam/musique\", \"answerable\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsd = load_dataset(\"bdsaglam/musique-mini\", \"answerable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mini_ids = dsd['train']['id']\n",
    "val_mini_ids = dsd['validation']['id']\n",
    "mini_ids = train_mini_ids + val_mini_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that samples from the dataset with equal distribution of n_hops\n",
    "def sample_evenly_with_exclude(dataset, n_samples, exclude_ids):\n",
    "    dataset = dataset.map(lambda x: {'n_hops': len(x['question_decomposition'])})\n",
    "    n_hops = np.unique(dataset['n_hops'])\n",
    "    samples_per_hop = n_samples // len(n_hops)\n",
    "    for hop in n_hops:\n",
    "        hop_samples = dataset.filter(lambda x: x['n_hops'] == hop and x['id'] not in exclude_ids).shuffle().select(range(samples_per_hop))\n",
    "        yield from hop_samples\n",
    "\n",
    "def publish_sweep_variant(path: str, config_name: str, n_samples: int):\n",
    "    dsd = load_dataset(path, config_name)\n",
    "    target_dsd = DatasetDict()\n",
    "    for split, ds in dsd.items():\n",
    "        target_dsd[split] = Dataset.from_list(list(sample_evenly_with_exclude(ds, n_samples, mini_ids)))\n",
    "    target_dsd.push_to_hub(f\"{path}-sweep\", config_name=config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish_sweep_variant(\"bdsaglam/musique\", \"default\", 300)\n",
    "# publish_sweep_variant(\"bdsaglam/musique\", \"answerable\", 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The subset used in my thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_thesis_variant(path: str, config_name: str, record_ids: list[str]):\n",
    "    dsd = load_dataset(path, config_name)\n",
    "    target_dsd = DatasetDict()\n",
    "    for split, ds in dsd.items():\n",
    "        ds_subset = ds.filter(lambda x: x['id'] in record_ids)\n",
    "        if not len(ds_subset):\n",
    "            continue\n",
    "        target_dsd[split] = ds_subset\n",
    "    target_dsd.push_to_hub(f\"{path}-thesis\", config_name=config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bellem.musique.constants import ABLATION_RECORD_IDS\n",
    "\n",
    "# publish_thesis_variant(\"bdsaglam/musique\", \"answerable\", ABLATION_RECORD_IDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
