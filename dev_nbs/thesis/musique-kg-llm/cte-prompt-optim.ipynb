{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "from bellem.utils import set_seed, jprint\n",
    "from bellem.musique.singlehop import benchmark\n",
    "\n",
    "set_seed(89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>question</th>\n",
       "      <th>question_decomposition</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_aliases</th>\n",
       "      <th>answerable</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2hop__128801_205185</td>\n",
       "      <td>[{'idx': 0, 'title': 'Pama, Burkina Faso', 'pa...</td>\n",
       "      <td>What county is the town where KNFM is licensed...</td>\n",
       "      <td>[{'id': 128801, 'question': 'What town is KNFM...</td>\n",
       "      <td>Midland County</td>\n",
       "      <td>[Midland County, Midland County, Texas]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Midland County, Midland County, Texas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2hop__719559_217649</td>\n",
       "      <td>[{'idx': 0, 'title': 'Antoine Marchand', 'para...</td>\n",
       "      <td>What's the record label of the artist who put ...</td>\n",
       "      <td>[{'id': 719559, 'question': 'Me and Julio Down...</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>[Warner Bros.]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Warner Bros.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2hop__128806_205185</td>\n",
       "      <td>[{'idx': 0, 'title': 'Spanish Town', 'paragrap...</td>\n",
       "      <td>What region is the town where KQRX is liscense...</td>\n",
       "      <td>[{'id': 128806, 'question': 'What town is KQRX...</td>\n",
       "      <td>Midland County</td>\n",
       "      <td>[Midland County, Midland County, Texas]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Midland County, Midland County, Texas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2hop__837090_278127</td>\n",
       "      <td>[{'idx': 0, 'title': 'The Opening (album)', 'p...</td>\n",
       "      <td>What is the record label of the Do It Again pe...</td>\n",
       "      <td>[{'id': 837090, 'question': 'Do It Again &gt;&gt; pe...</td>\n",
       "      <td>Roc-A-Fella Records</td>\n",
       "      <td>[Roc-A-Fella Records]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Roc-A-Fella Records]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2hop__128895_11424</td>\n",
       "      <td>[{'idx': 0, 'title': 'Ehrhardt, South Carolina...</td>\n",
       "      <td>How many households were there in the town WPU...</td>\n",
       "      <td>[{'id': 128895, 'question': 'What town is WPUR...</td>\n",
       "      <td>15,504</td>\n",
       "      <td>[15,504]</td>\n",
       "      <td>True</td>\n",
       "      <td>[15,504]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         paragraphs  \\\n",
       "0  2hop__128801_205185  [{'idx': 0, 'title': 'Pama, Burkina Faso', 'pa...   \n",
       "1  2hop__719559_217649  [{'idx': 0, 'title': 'Antoine Marchand', 'para...   \n",
       "2  2hop__128806_205185  [{'idx': 0, 'title': 'Spanish Town', 'paragrap...   \n",
       "3  2hop__837090_278127  [{'idx': 0, 'title': 'The Opening (album)', 'p...   \n",
       "4   2hop__128895_11424  [{'idx': 0, 'title': 'Ehrhardt, South Carolina...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What county is the town where KNFM is licensed...   \n",
       "1  What's the record label of the artist who put ...   \n",
       "2  What region is the town where KQRX is liscense...   \n",
       "3  What is the record label of the Do It Again pe...   \n",
       "4  How many households were there in the town WPU...   \n",
       "\n",
       "                              question_decomposition               answer  \\\n",
       "0  [{'id': 128801, 'question': 'What town is KNFM...       Midland County   \n",
       "1  [{'id': 719559, 'question': 'Me and Julio Down...         Warner Bros.   \n",
       "2  [{'id': 128806, 'question': 'What town is KQRX...       Midland County   \n",
       "3  [{'id': 837090, 'question': 'Do It Again >> pe...  Roc-A-Fella Records   \n",
       "4  [{'id': 128895, 'question': 'What town is WPUR...               15,504   \n",
       "\n",
       "                            answer_aliases  answerable  \\\n",
       "0  [Midland County, Midland County, Texas]        True   \n",
       "1                           [Warner Bros.]        True   \n",
       "2  [Midland County, Midland County, Texas]        True   \n",
       "3                    [Roc-A-Fella Records]        True   \n",
       "4                                 [15,504]        True   \n",
       "\n",
       "                                   answers  \n",
       "0  [Midland County, Midland County, Texas]  \n",
       "1                           [Warner Bros.]  \n",
       "2  [Midland County, Midland County, Texas]  \n",
       "3                    [Roc-A-Fella Records]  \n",
       "4                                 [15,504]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../../data/generated/musique-common/base-dataset-train.jsonl', orient='records', lines=True)\n",
    "df = df.iloc[:10].copy()\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_retrieval_func = lambda docs, query: [doc for doc in docs if doc['is_supporting']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPTS = [\n",
    "    {\n",
    "        \"description\": \"Baseline\",\n",
    "        \"prompt\": \"\"\"You are an excellent question-answering system known for providing accurate and reliable answers. Your responses should be solely based on the context information given, without drawing on prior knowledge.\n",
    "\n",
    "Before answering the question, first, you extract relevant entity-relation-entity triplets from the context. Then, you answer the question based on the triplets.\"\"\".strip(),\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Enhanced Entity Extraction for Q&A\",\n",
    "        \"prompt\": \"As a sophisticated question-answering system, your primary task is to deliver precise and trustworthy answers. Begin by analyzing the provided text to identify and extract key entity-relation-entity triplets. Use these triplets exclusively to construct your response to the question, ensuring that your answers are based strictly on the extracted information and not on external knowledge.\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Context-focused Q&A System\",\n",
    "        \"prompt\": \"You are a reliable question-answering model designed to provide accurate responses based on specific text input. First, process the given context to systematically extract entity-relation-entity triplets. Subsequently, utilize these triplets to answer questions directly related to the context, avoiding the use of any information not explicitly mentioned in the text.\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Triplets-based Answer Generation\",\n",
    "        \"prompt\": \"As an advanced question-answering system, you are expected to offer precise answers by strictly adhering to the information provided in the context. Start by identifying entity-relation-entity triplets within the text. These triplets will form the basis of your answers, ensuring that all responses are directly derived from the text and do not incorporate any prior knowledge.\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Entity-Relation Analysis for Accurate Q&A\",\n",
    "        \"prompt\": \"Your role as a question-answering system is to provide reliable and exact answers by analyzing textual content. Initially, dissect the context to identify all relevant entity-relation-entity triplets. Answer the posed questions by referencing these triplets, maintaining a strict focus on the extracted data without referencing external information.\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Focused Entity Extraction for Contextual Answers\",\n",
    "        \"prompt\": \"As a high-performing question-answering interface, your task is to process textual content meticulously to identify entity-relation-entity triplets. Utilize these triplets to frame your responses to ensure that your answers remain grounded in the provided context and are independent of any pre-existing knowledge.\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Precision-focused Triplet Extraction Q&A\",\n",
    "        \"prompt\": \"You are an advanced question-answering system designed to provide precise responses. Start by pinpointing and extracting only the most essential entity-relation-entity triplets from the provided context. Use these pivotal triplets as the sole basis for your answers, ensuring a direct and focused response that does not incorporate external knowledge.\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Key Triplet Analysis for Direct Q&A\",\n",
    "        \"prompt\": \"As a specialized question-answering system, your role is to deliver highly accurate answers by first identifying key entity-relation-entity triplets within the text. Focus on these core triplets to formulate your answers, ensuring they are tightly aligned with the context's specific details without referencing any outside information.\",\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Strategic Entity-Relation Extraction for Enhanced Q&A\",\n",
    "        \"prompt\": \"Operate as a precise question-answering model, focusing on extracting strategic entity-relation-entity triplets from the text. Answer questions using these selected triplets to maintain a strong alignment with the provided context, ensuring your responses are detailed, accurate, and confined to the given information.\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_SUFFIX = \"\"\"\n",
    "# Output format\n",
    "Triplets: [A list of entity-relation-entity triplets extracted from the context.]\n",
    "Answer: [answer in 2-4 words]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = [\n",
    "    {\n",
    "        \"context\": \"\"\"Glenhis Hernández (born 7 October 1990 in Havana) is a taekwondo practitioner from Cuba. She was the 2013 World\n",
    "Champion in middleweight.\n",
    "\n",
    "The current mayor of Havana (\"President of the People's Power Provincial Assembly\") is Marta Hernández Romero, she\n",
    "was elected on March 5, 2011.\"\"\",\n",
    "        \"question\": \"Who is the current mayor of Havana?\",\n",
    "        \"generation\": \"\"\"Triplets: \n",
    "Glenhis Hernández | birth place | Havana\n",
    "Marta Hernández Romero | serves as | mayor of Havana\n",
    "\n",
    "Answer: Marta Hernández Romero\"\"\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "USER_PROMPT = \"\"\"The context information is provided below.\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the question.\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "def answer_question_cte(\n",
    "    context: str,\n",
    "    question: str,\n",
    "    model_name: str = \"gpt-3.5-turbo\",\n",
    "    completion_kwargs: dict | None = None,\n",
    "    client=None,\n",
    "    system_prompt: str = \"\",\n",
    "    examples: list = EXAMPLES,\n",
    ") -> dict:\n",
    "    if client is None:\n",
    "        client = openai.Client()\n",
    "\n",
    "    completion_kwargs = completion_kwargs or {}\n",
    "    \n",
    "    # Prepare the messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "    ]\n",
    "    for example in examples:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": USER_PROMPT.format(context=example[\"context\"], question=example[\"question\"]),\n",
    "            }\n",
    "        )\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": example[\"generation\"],\n",
    "            }\n",
    "        )\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": USER_PROMPT.format(context=context, question=question),\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    # Generate the response\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        **completion_kwargs,\n",
    "    )\n",
    "    generation = chat_completion.choices[0].message.content\n",
    "    \n",
    "    # Parse the response\n",
    "    answer = \"\"\n",
    "    triplets = []\n",
    "    for line in generation.splitlines():\n",
    "        if line.startswith(\"Answer:\"):\n",
    "            answer = line.split(\"Answer:\")[1].strip()\n",
    "        elif \"|\" in line:\n",
    "            triplets.append(line.strip())\n",
    "    return dict(triplets=triplets, answer=answer, generation=generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for system_prompt_config in SYSTEM_PROMPTS:\n",
    "    prompt_name = system_prompt_config[\"description\"]\n",
    "    system_prompt = system_prompt_config[\"prompt\"] + \"\\n\" + SYSTEM_PROMPT_SUFFIX\n",
    "    qa_func = partial(answer_question_cte, system_prompt=system_prompt)\n",
    "    for i in range(1, N_RUNS+1):\n",
    "        df_cte, scores = benchmark(df, qa_func, perfect_retrieval_func, ignore_errors=False)\n",
    "        results.append({**scores, 'prompt': prompt_name, \"run\": i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">exact_match</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Context-focused Q&amp;A System</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.019245</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enhanced Entity Extraction for Q&amp;A</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entity-Relation Analysis for Accurate Q&amp;A</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Focused Entity Extraction for Contextual Answers</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key Triplet Analysis for Direct Q&amp;A</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision-focused Triplet Extraction Q&amp;A</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strategic Entity-Relation Extraction for Enhanced Q&amp;A</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triplets-based Answer Generation</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   exact_match                 \\\n",
       "                                                          mean       std  min   \n",
       "prompt                                                                          \n",
       "Baseline                                              0.800000  0.000000  0.8   \n",
       "Context-focused Q&A System                            0.766667  0.057735  0.7   \n",
       "Enhanced Entity Extraction for Q&A                    0.800000  0.000000  0.8   \n",
       "Entity-Relation Analysis for Accurate Q&A             0.766667  0.057735  0.7   \n",
       "Focused Entity Extraction for Contextual Answers      0.733333  0.057735  0.7   \n",
       "Key Triplet Analysis for Direct Q&A                   0.766667  0.057735  0.7   \n",
       "Precision-focused Triplet Extraction Q&A              0.700000  0.000000  0.7   \n",
       "Strategic Entity-Relation Extraction for Enhanc...    0.766667  0.057735  0.7   \n",
       "Triplets-based Answer Generation                      0.733333  0.057735  0.7   \n",
       "\n",
       "                                                               f1            \\\n",
       "                                                    max      mean       std   \n",
       "prompt                                                                        \n",
       "Baseline                                            0.8  0.800000  0.000000   \n",
       "Context-focused Q&A System                          0.8  0.788889  0.019245   \n",
       "Enhanced Entity Extraction for Q&A                  0.8  0.800000  0.000000   \n",
       "Entity-Relation Analysis for Accurate Q&A           0.8  0.766667  0.057735   \n",
       "Focused Entity Extraction for Contextual Answers    0.8  0.755556  0.050918   \n",
       "Key Triplet Analysis for Direct Q&A                 0.8  0.766667  0.057735   \n",
       "Precision-focused Triplet Extraction Q&A            0.7  0.750000  0.000000   \n",
       "Strategic Entity-Relation Extraction for Enhanc...  0.8  0.775000  0.043301   \n",
       "Triplets-based Answer Generation                    0.8  0.755556  0.050918   \n",
       "\n",
       "                                                                    \n",
       "                                                         min   max  \n",
       "prompt                                                              \n",
       "Baseline                                            0.800000  0.80  \n",
       "Context-focused Q&A System                          0.766667  0.80  \n",
       "Enhanced Entity Extraction for Q&A                  0.800000  0.80  \n",
       "Entity-Relation Analysis for Accurate Q&A           0.700000  0.80  \n",
       "Focused Entity Extraction for Contextual Answers    0.700000  0.80  \n",
       "Key Triplet Analysis for Direct Q&A                 0.700000  0.80  \n",
       "Precision-focused Triplet Extraction Q&A            0.750000  0.75  \n",
       "Strategic Entity-Relation Extraction for Enhanc...  0.725000  0.80  \n",
       "Triplets-based Answer Generation                    0.700000  0.80  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df = pd.DataFrame.from_records(results, columns=['prompt', 'run', 'exact_match', 'f1'])\n",
    "report_df.drop(columns=['run']).groupby(['prompt']).agg(['mean', 'std', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| prompt                                                |   exact_match |       f1 |\n",
      "|:------------------------------------------------------|--------------:|---------:|\n",
      "| Baseline                                              |      0.8      | 0.8      |\n",
      "| Context-focused Q&A System                            |      0.766667 | 0.788889 |\n",
      "| Enhanced Entity Extraction for Q&A                    |      0.8      | 0.8      |\n",
      "| Entity-Relation Analysis for Accurate Q&A             |      0.766667 | 0.766667 |\n",
      "| Focused Entity Extraction for Contextual Answers      |      0.733333 | 0.755556 |\n",
      "| Key Triplet Analysis for Direct Q&A                   |      0.766667 | 0.766667 |\n",
      "| Precision-focused Triplet Extraction Q&A              |      0.7      | 0.75     |\n",
      "| Strategic Entity-Relation Extraction for Enhanced Q&A |      0.766667 | 0.775    |\n",
      "| Triplets-based Answer Generation                      |      0.733333 | 0.755556 |\n"
     ]
    }
   ],
   "source": [
    "print(report_df.drop(columns=['run']).groupby(['prompt']).mean().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_mask = ~(df_cte['fuzzy_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Columbia Records\n",
       "7          Hear Music\n",
       "Name: predicted_answer, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cte.loc[fail_mask]['predicted_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 2\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[43mdf_cte\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfail_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/pandas/core/indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/baris/lib/python3.10/site-packages/pandas/core/indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "row = df_cte.loc[fail_mask].iloc[i]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(row['question'])\n",
    "print(row['answers'])\n",
    "\n",
    "print(\"=\"*80)\n",
    "jprint(row['raw_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
