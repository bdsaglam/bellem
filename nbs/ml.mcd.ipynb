{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCD\n",
    "> Maximum Classifier Discrepancy for Unsupervised Domain Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ml.mcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from bellek.ml.layer import GradReverse\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.learner import CancelBatchException, CancelStepException\n",
    "from fastai.learner import Learner, Recorder\n",
    "from fastai.losses import BaseLoss, CrossEntropyLossFlat\n",
    "from fastai.torch_core import default_device\n",
    "from fastcore.basics import GetAttr, store_attr\n",
    "from fastcore.meta import delegates\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def discrepancy(a, b):\n",
    "    return torch.mean(torch.abs(F.softmax(a, dim=-1) - F.softmax(b, dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "test_eq(discrepancy(a, a).item(), 0.0)\n",
    "assert discrepancy(a, -a).item() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DiscrepancyLoss:\n",
    "    def __call__(self, outs, *targets, **kwargs):\n",
    "        assert len(outs) == 2\n",
    "        return -discrepancy(*outs)\n",
    "\n",
    "def discrepancy_metric(pred, *targets):\n",
    "    a, b = pred[-2], pred[-1]\n",
    "    return discrepancy(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Feature(nn.Module):\n",
    "    \"Image feature extractor\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(8192, 3072)\n",
    "        self.bn1_fc = nn.BatchNorm1d(3072)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), stride=2, kernel_size=3, padding=1)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), stride=2, kernel_size=3, padding=1)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), 8192)\n",
    "        x = F.relu(self.bn1_fc(self.fc1(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        return x\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    \"Classifier on image features\"\n",
    "\n",
    "    def __init__(self, prob=0.5, lambd=1.0):\n",
    "        super().__init__()\n",
    "        self.prob = prob\n",
    "        self.lambd = lambd\n",
    "        self.fc1 = nn.Linear(8192, 3072)\n",
    "        self.bn1_fc = nn.BatchNorm1d(3072)\n",
    "        self.fc2 = nn.Linear(3072, 2048)\n",
    "        self.bn2_fc = nn.BatchNorm1d(2048)\n",
    "        self.fc3 = nn.Linear(2048, 10)\n",
    "        self.bn_fc3 = nn.BatchNorm1d(10)\n",
    "        self.gr = GradReverse(lambd)\n",
    "\n",
    "    def forward(self, x, grad_reverse=False):\n",
    "        if grad_reverse:\n",
    "            x = self.gr(x)\n",
    "        x = F.relu(self.bn2_fc(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class McdDataset:\n",
    "    \"\"\"Dataset for MCD. \n",
    "    A data point is a tuple of 4 tensors, in the following order:\n",
    "    \n",
    "    (source_domain_x, target_domain_x, source_domain_y, target_domain_y)\n",
    "    \"\"\"\n",
    "    def __init__(self, source_ds, target_ds):\n",
    "        store_attr()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        xs, ys = self.source_ds[idx]\n",
    "        xt, yt = self.target_ds[idx]\n",
    "        return xs, xt, ys, yt\n",
    "    \n",
    "    def __len__(self):\n",
    "        return min(len(self.source_ds), len(self.target_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class McdDataLoader(GetAttr):\n",
    "    \"\"\"Dataloader for MCD.\"\"\"\n",
    "    \n",
    "    _default = 'source_dl'\n",
    "\n",
    "    def __init__(self, source_dl, target_dl):\n",
    "        store_attr()\n",
    "        self.source_it = None\n",
    "        self.target_it = None\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.source_it = iter(self.source_dl)\n",
    "        self.target_it = iter(self.target_dl)\n",
    "        return self\n",
    "    \n",
    "    def __len__(self):\n",
    "        return min(len(self.source_dl), len(self.target_dl))\n",
    "    \n",
    "    def __next__(self):\n",
    "        xsb, ysb = next(self.source_it)\n",
    "        xtb, ytb = next(self.target_it)\n",
    "        return xsb, xtb, ysb, ytb\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.source_dl.to(device)\n",
    "        self.target_dl.to(device)\n",
    "    \n",
    "    def new(self, dataset=None, cls=None, **kwargs):\n",
    "        if cls is None: cls = type(self)\n",
    "        return cls(self.source_dl.new(**kwargs), self.source_dl.new(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class McdModel(nn.Module):\n",
    "    \"\"\"Image classification model with a gradient reversal layer and two classifier heads.\"\"\"\n",
    "\n",
    "    def __init__(self, feature_extractor, classifier1, classifier2, lambd=1.0):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "        self.gr = GradReverse(lambd)\n",
    "    \n",
    "    def forward(self, img, grad_reverse=False):\n",
    "        feat = self.feature_extractor(img)\n",
    "        if grad_reverse:\n",
    "            feat = self.gr(feat)\n",
    "        output1 = self.classifier1(feat)\n",
    "        output2 = self.classifier2(feat)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class EnsembleMcdModel(nn.Module):\n",
    "    \"\"\"Ensemble of two classifiers trained by MCD.\"\"\"\n",
    "\n",
    "    def __init__(self, feature_extractor, classifier1, classifier2):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "    \n",
    "    def forward(self, img):\n",
    "        feat = self.feature_extractor(img)\n",
    "        output1 = self.classifier1(feat)\n",
    "        output2 = self.classifier2(feat)\n",
    "        return (output1 + output2) / 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_mcd_model(cls, mcd_model):\n",
    "        return cls(mcd_model.feature_extractor, mcd_model.classifier1, mcd_model.classifier2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class McdCallback(Callback):\n",
    "    \"\"\"It expects data in the form of `McdDataset`.\"\"\"\n",
    "    order = Recorder.order + 10\n",
    "\n",
    "    def __init__(self, classification_loss_func, discrepancy_loss_func):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "    \n",
    "    def before_batch(self):\n",
    "        self._do_one_batch()\n",
    "        raise CancelBatchException\n",
    "\n",
    "    def before_fit(self):\n",
    "        \"Set device for loss funcs\"\n",
    "        device = getattr(self.dls, 'device', default_device())\n",
    "        if isinstance(self.classification_loss_func, (nn.Module, BaseLoss)): \n",
    "            self.classification_loss_func.to(device)\n",
    "        if isinstance(self.discrepancy_loss_func, (nn.Module, BaseLoss)): \n",
    "            self.discrepancy_loss_func.to(device)\n",
    "    \n",
    "    def _do_one_batch(self):\n",
    "        assert len(self.xb) == 2\n",
    "        assert len(self.yb) == 2\n",
    "        source_pred, source_loss = self._predict_source()\n",
    "        target_pred, target_loss = self._predict_target()\n",
    "        self.learn.pred = tuple([*source_pred, *target_pred])\n",
    "        self.learn('after_pred')\n",
    "        if source_loss is not None and target_loss is not None:\n",
    "            self.learn.loss = source_loss.detach().cpu() + target_loss.detach().cpu()\n",
    "        self.learn('after_loss')\n",
    "        if not self.training or not len(self.yb): \n",
    "            return\n",
    "        self._do_grad_opt()\n",
    "    \n",
    "    def _predict_source(self):\n",
    "        img = self.xb[0]\n",
    "        pred = self.model(img, grad_reverse=False)\n",
    "        loss = None\n",
    "        if len(self.yb):\n",
    "            loss = self.classification_loss_func(pred, *self.yb)\n",
    "            if self.training:\n",
    "                loss.backward(retain_graph=True)\n",
    "        return pred, loss\n",
    "    \n",
    "    def _predict_target(self):\n",
    "        img = self.xb[1]\n",
    "        pred = self.model(img, grad_reverse=True)\n",
    "        loss = None\n",
    "        if len(self.yb):\n",
    "            loss = self.discrepancy_loss_func(pred, *self.yb)\n",
    "            if self.training:\n",
    "                loss.backward()\n",
    "        return pred, loss\n",
    "\n",
    "    def _do_grad_opt(self):\n",
    "        self._with_events(self.learn.opt.step, 'step', CancelStepException)\n",
    "        self.learn.opt.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "@delegates(Learner.__init__)\n",
    "def mcd_learner(\n",
    "        dls:DataLoaders, # `DataLoaders` containing fastai or PyTorch `DataLoader`s\n",
    "        model:Callable, # PyTorch model for training or inference\n",
    "        **kwargs\n",
    "    ):\n",
    "    \"\"\"Creates a Learner for MCD by arranging loss functions, metrics, and adding `McdCallback` to callbacks.\"\"\"\n",
    "    from fastmtl.loss import CombinedLoss, LossRouting\n",
    "    from fastmtl.metric import route_to_metric\n",
    "    from fastai.metrics import accuracy\n",
    "    \n",
    "    source_classification_loss_func = CombinedLoss(\n",
    "        LossRouting(CrossEntropyLossFlat(), pred_idx=0, target_idx=0, weight=1.0),\n",
    "        LossRouting(CrossEntropyLossFlat(), pred_idx=1, target_idx=0, weight=1.0),\n",
    "    )\n",
    "    discrepancy_loss_func = DiscrepancyLoss()\n",
    "    mcd_callback = McdCallback(source_classification_loss_func, discrepancy_loss_func)\n",
    "    cbs = [mcd_callback, *list(kwargs.pop('cbs', []))]\n",
    "\n",
    "    classification_metrics = [route_to_metric(accuracy, 0, 0), route_to_metric(accuracy, 1, 0)]\n",
    "    discrepancy_metrics = [route_to_metric(accuracy, 2, 1), route_to_metric(accuracy, 3, 1), discrepancy_metric] \n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        loss_func=source_classification_loss_func,\n",
    "        metrics=[*classification_metrics, *discrepancy_metrics],\n",
    "        cbs=cbs,\n",
    "        **kwargs,\n",
    "    )\n",
    "    for metric, name in zip(\n",
    "        learn.metrics, \n",
    "        ['clf1_acc_s', 'clf2_acc_s', 'clf1_acc_t', 'clf2_acc_t', 'discrep_t']\n",
    "    ):\n",
    "        try:\n",
    "            metric.name = name\n",
    "        except AttributeError:\n",
    "            metric.func.__name__ = name\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
