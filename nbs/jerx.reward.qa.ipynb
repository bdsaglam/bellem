{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA reward model JERX task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp jerx.reward.qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import os\n",
    "\n",
    "from openai import BadRequestError, OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from bellem.logging import get_logger\n",
    "from bellem.text.utils import fuzzy_match\n",
    "\n",
    "log = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "import json\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"You are an excellent Q&A system that is trusted around the world. You are given a question that requires multi-hop reasoning. Always answer the question using the provided context information, and not prior knowledge.\n",
    "\n",
    "Some rules to follow:\n",
    "1. Never directly reference the given context in your answer.\n",
    "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
    "\n",
    "Output format:\n",
    "Your output must be a single line in JSON such as:\n",
    "{\"reasoning\": \"Provide step by step multi-hop reasoning for the answer.\", \"answer\": \"Provide the final answer in 2-4 words.\"}\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"The context information below is provided as a set of entity-relation-entity triplets from knowledge graph.\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the question.\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class QuestionAnsweringResult(BaseModel):\n",
    "    \"\"\"Data model for answering the question.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(description=\"Multi-hop reasoning for the answer.\")\n",
    "    answer: str = Field(description=\"The answer to the question in 2-4 words.\")\n",
    "    raw_output: str = Field(description=\"The raw output from the model.\")\n",
    "\n",
    "\n",
    "def make_question_answer_func(\n",
    "    model_name: str = \"gpt-3.5-turbo\",\n",
    "    client: OpenAI = None,\n",
    "    completion_kwargs: dict | None = None,\n",
    "):\n",
    "    if client is None:\n",
    "        client = OpenAI()\n",
    "\n",
    "    if completion_kwargs is None:\n",
    "        completion_kwargs = {}\n",
    "\n",
    "    def func(context: str, question: str) -> QuestionAnsweringResult:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": DEFAULT_SYSTEM_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": USER_PROMPT.format(context=context, question=question),\n",
    "            },\n",
    "        ]\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            **completion_kwargs,\n",
    "        )\n",
    "        text = chat_completion.choices[0].message.content\n",
    "        try:\n",
    "            output = json.loads(text)\n",
    "        except json.JSONDecodeError:\n",
    "            log.error(\"Failed to decode the JSON output: %s\", text)\n",
    "            output = {}\n",
    "        return QuestionAnsweringResult(\n",
    "            answer=output.get(\"answer\", \"N/A\"),\n",
    "            reasoning=output.get(\"reasoning\", \"\"),\n",
    "            raw_output=text,\n",
    "        )\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class RewardAssessment(QuestionAnsweringResult):\n",
    "    reward: float = Field(description=\"The reward value for the answer.\")\n",
    "\n",
    "def make_qa_reward_func(model_name: str = \"gpt-3.5-turbo\", answer_comparator=fuzzy_match, completion_kwargs: dict | None = None):\n",
    "    qa = make_question_answer_func(model_name, completion_kwargs=completion_kwargs)\n",
    "\n",
    "    def reward(context: str, question: str, answers: list[str]) -> RewardAssessment:\n",
    "        try:\n",
    "            qa_result = qa(context, question)\n",
    "        except BadRequestError as e:\n",
    "            log.warning(f\"Failed to assess generation: {e}\")\n",
    "            return RewardAssessment(answer=\"\", reasoning=str(e), reward=0.0)\n",
    "        correct = any(answer_comparator(qa_result.answer, answer) for answer in answers)\n",
    "        reward = 1.0 if correct else 0.0\n",
    "        return RewardAssessment(**qa_result.dict(), reward=reward)\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringResult(reasoning='1. Dominica first competed at Olympic Games in 1996. 2. River Quanery is found in Dominica.', answer='1996', raw_output='{\"reasoning\": \"1. Dominica first competed at Olympic Games in 1996. 2. River Quanery is found in Dominica.\", \"answer\": \"1996\"}')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets = [ \"Dominica | first competed at | Olympic Games in 1996\", \"Dominica | has participated in | each Games since then\", \"Dominica | has not won | any medals at the Olympic Games\" ]\n",
    "\n",
    "context = \"\\n\".join(triplets)\n",
    "question = \"When did the country where the River Quanery is found first compete in Olympic games?\"\n",
    "answer = \"1996\"\n",
    "\n",
    "qa = make_question_answer_func()\n",
    "qa(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_func = make_qa_reward_func(\"gpt-3.5-turbo\")\n",
    "result = reward_func(context, question, [answer])\n",
    "assert result.reward == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_func = make_qa_reward_func(\"gpt-4-turbo\")\n",
    "result = reward_func(context, question, [answer])\n",
    "assert result.reward == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
