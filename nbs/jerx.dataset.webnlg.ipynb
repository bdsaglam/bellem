{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset utils for joint entity relation extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp jerx.dataset.webnlg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from bellek.utils import split_camel_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "def _transform_relation(relation: str):\n",
    "    return \" \".join([word.lower() for word in split_camel_case(relation)]).strip()\n",
    "\n",
    "\n",
    "def _transform_entity(entity: str):\n",
    "    return entity.replace(\"_\", \" \").strip()\n",
    "\n",
    "\n",
    "def _transform_triplet(triplet_string: str):\n",
    "    delimiter = \" | \"\n",
    "    triplet_string = triplet_string.replace('\"', \"\").replace(\"''\", \"\")\n",
    "    entity1, relation, entity2 = triplet_string.split(delimiter)\n",
    "    relation = _transform_relation(relation)\n",
    "    entity1 = _transform_entity(entity1)\n",
    "    entity2 = _transform_entity(entity2)\n",
    "    return delimiter.join([entity1, relation, entity2])\n",
    "\n",
    "\n",
    "def _batch_transform_webnlg(examples):\n",
    "    for lex, mts in zip(examples[\"lex\"], examples[\"modified_triple_sets\"]):\n",
    "        for text in lex[\"text\"]:\n",
    "            triplets = [_transform_triplet(triplet_string) for triplet_string in mts[\"mtriple_set\"][0]]\n",
    "            yield dict(text=text, triplets=triplets)\n",
    "\n",
    "\n",
    "def batch_transform_webnlg(examples):\n",
    "    records = list(_batch_transform_webnlg(examples))\n",
    "    return {\n",
    "        \"text\": [record[\"text\"] for record in records],\n",
    "        \"triplets\": [record[\"triplets\"] for record in records],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a96a9aa6c2433986625871fb566497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The Aarhus is the airport of Aarhus, Denmark.', 'triplets': ['Aarhus Airport|city served|Aarhus, Denmark']}\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"web_nlg\", \"release_v3.0_en\", split=\"train[:10]\")\n",
    "jerx_ds = ds.map(batch_transform_webnlg, batched=True, remove_columns=ds.column_names)\n",
    "\n",
    "assert 'text' in jerx_ds.features\n",
    "assert 'triplets' in jerx_ds.features\n",
    "assert isinstance(jerx_ds[0]['triplets'], list)\n",
    "assert isinstance(jerx_ds[0]['triplets'][0], str)\n",
    "print(jerx_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
