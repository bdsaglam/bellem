{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward model JERX task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp jerx.reward.llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import os\n",
    "\n",
    "from openai import BadRequestError, OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from bellek.logging import get_logger\n",
    "from bellek.text.utils import fuzzy_match\n",
    "\n",
    "log = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "import json\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"You are an excellent Q&A system that is trusted around the world. You are given a question that requires multi-hop reasoning. Always answer the question using the provided context information, and not prior knowledge.\n",
    "\n",
    "Some rules to follow:\n",
    "1. Never directly reference the given context in your answer.\n",
    "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
    "\n",
    "Output format:\n",
    "Your output must be a single line in JSON such as:\n",
    "{\"reasoning\": \"Provide step by step multi-hop reasoning for the answer.\", \"answer\": \"Provide the final answer in 2-4 words.\"}\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"The context information below is provided as a set of entity-relation-entity triplets from knowledge graph.\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the question.\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class QuestionAnsweringResult(BaseModel):\n",
    "    \"\"\"Data model for answering the question.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(description=\"Multi-hop reasoning for the answer.\")\n",
    "    answer: str = Field(description=\"The answer to the question in 2-4 words.\")\n",
    "    raw_output: str = Field(description=\"The raw output from the model.\")\n",
    "\n",
    "\n",
    "def make_question_answer_func(\n",
    "    model_name: str = \"gpt-3.5-turbo\",\n",
    "    client: OpenAI = None,\n",
    "    completion_kwargs: dict | None = None,\n",
    "):\n",
    "    if client is None:\n",
    "        client = OpenAI()\n",
    "\n",
    "    if completion_kwargs is None:\n",
    "        completion_kwargs = {}\n",
    "\n",
    "    def func(context: str, question: str) -> QuestionAnsweringResult:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": DEFAULT_SYSTEM_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": USER_PROMPT.format(context=context, question=question),\n",
    "            },\n",
    "        ]\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            **completion_kwargs,\n",
    "        )\n",
    "        text = chat_completion.choices[0].message.content\n",
    "        output = json.loads(text)\n",
    "        return QuestionAnsweringResult(\n",
    "            answer=output.get(\"answer\", \"N/A\"),\n",
    "            reasoning=output.get(\"reasoning\", \"\"),\n",
    "            raw_output=text,\n",
    "        )\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class RewardAssessment(QuestionAnsweringResult):\n",
    "    reward: float = Field(description=\"The reward value for the answer.\")\n",
    "\n",
    "def make_reward_func(model_name: str = \"gpt-3.5-turbo\", answer_comparator=fuzzy_match, completion_kwargs: dict | None = None):\n",
    "    qa = make_question_answer_func(model_name, completion_kwargs=completion_kwargs)\n",
    "\n",
    "    def reward(context: str, question: str, answers: list[str]) -> RewardAssessment:\n",
    "        try:\n",
    "            qa_result = qa(context, question)\n",
    "        except BadRequestError as e:\n",
    "            log.warning(f\"Failed to assess generation: {e}\")\n",
    "            return RewardAssessment(answer=\"\", reasoning=str(e), reward=0.0)\n",
    "        correct = any(answer_comparator(qa_result.answer, answer) for answer in answers)\n",
    "        reward = 1.0 if correct else 0.0\n",
    "        return RewardAssessment(**qa_result.dict(), reward=reward)\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringResult(reasoning='Dominica first competed at the Olympic Games in 1996 and has participated in every Games since then.', answer='1996', raw_output='{\\n\"reasoning\": \"Dominica first competed at the Olympic Games in 1996 and has participated in every Games since then.\",\\n\"answer\": \"1996\"\\n}')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets = [ \"Dominica | first competed at | Olympic Games in 1996\", \"Dominica | has participated in | each Games since then\", \"Dominica | has not won | any medals at the Olympic Games\" ]\n",
    "\n",
    "context = \"\\n\".join(triplets)\n",
    "question = \"When did the country where the River Quanery is found first compete in Olympic games?\"\n",
    "answer = \"1996\"\n",
    "\n",
    "qa = make_question_answer_func()\n",
    "qa(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_func = make_reward_func(\"gpt-3.5-turbo\")\n",
    "result = reward_func(context, question, [answer])\n",
    "assert result.reward == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_func = make_reward_func(\"gpt-4-turbo\")\n",
    "result = reward_func(context, question, [answer])\n",
    "assert result.reward == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
