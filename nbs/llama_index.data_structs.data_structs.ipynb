{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama-index data structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp llama_index.data_structs.data_structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "from llama_index.data_structs.struct_type import IndexStructType\n",
    "from llama_index.data_structs.data_structs import IndexStruct\n",
    "from bellem.text.utils import fuzzy_match\n",
    "from llama_index.schema import BaseNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "@dataclass\n",
    "class KG(IndexStruct):\n",
    "    \"\"\"A table of keywords mapping keywords to text chunks.\"\"\"\n",
    "\n",
    "    # Unidirectional\n",
    "\n",
    "    # table of keywords to node ids\n",
    "    table: Dict[str, Set[str]] = field(default_factory=dict)\n",
    "\n",
    "    # TODO: legacy attribute, remove in future releases\n",
    "    rel_map: Dict[str, List[List[str]]] = field(default_factory=dict)\n",
    "\n",
    "    # TBD, should support vector store, now we just persist the embedding memory\n",
    "    # maybe chainable abstractions for *_stores could be designed\n",
    "    embedding_dict: Dict[str, List[float]] = field(default_factory=dict)\n",
    "\n",
    "    # keyword match params\n",
    "    keyword_match_threshold: float = 0.6\n",
    "\n",
    "    @property\n",
    "    def node_ids(self) -> Set[str]:\n",
    "        \"\"\"Get all node ids.\"\"\"\n",
    "        return set.union(*self.table.values())\n",
    "\n",
    "    def add_to_embedding_dict(self, triplet_str: str, embedding: List[float]) -> None:\n",
    "        \"\"\"Add embedding to dict.\"\"\"\n",
    "        self.embedding_dict[triplet_str] = embedding\n",
    "\n",
    "    def add_node(self, keywords: List[str], node: BaseNode) -> None:\n",
    "        \"\"\"Add text to table.\"\"\"\n",
    "        node_id = node.node_id\n",
    "        for keyword in keywords:\n",
    "            if keyword not in self.table:\n",
    "                self.table[keyword] = set()\n",
    "            self.table[keyword].add(node_id)\n",
    "\n",
    "    def search_node_by_keyword(self, keyword: str) -> Dict[str, List[str]]:\n",
    "        result = dict()\n",
    "        for k, node_set in self.table.items():\n",
    "            if fuzzy_match(keyword, k, threshold=self.keyword_match_threshold):\n",
    "                result[k] = list(node_set)\n",
    "        return result\n",
    "    \n",
    "    @classmethod\n",
    "    def get_type(cls) -> IndexStructType:\n",
    "        \"\"\"Get type.\"\"\"\n",
    "        return IndexStructType.KG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def patch_kg_data_struct():\n",
    "    from llama_index.data_structs.registry import INDEX_STRUCT_TYPE_TO_INDEX_STRUCT_CLASS\n",
    "     \n",
    "    INDEX_STRUCT_TYPE_TO_INDEX_STRUCT_CLASS[IndexStructType.KG] =  KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
