{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama-index knowledge graph retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp llama_index.indices.knowledge_graph.retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from typing import Any, Callable, Dict, List, Optional, Set, Tuple\n",
    "\n",
    "from llama_index.callbacks.base import CallbackManager\n",
    "from llama_index.core.base_retriever import BaseRetriever\n",
    "from llama_index.indices.keyword_table.utils import extract_keywords_given_response\n",
    "from llama_index.indices.query.embedding_utils import get_top_k_embeddings\n",
    "from llama_index.prompts import BasePromptTemplate\n",
    "from llama_index.prompts.default_prompts import DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE\n",
    "from llama_index.schema import (\n",
    "    BaseNode,\n",
    "    MetadataMode,\n",
    "    NodeWithScore,\n",
    "    QueryBundle,\n",
    "    TextNode,\n",
    ")\n",
    "from llama_index.utils import print_text, truncate_text\n",
    "from llama_index.indices.knowledge_graph.retrievers import KGRetrieverMode\n",
    "from bellek.llama_index.indices.knowledge_graph.base import KnowledgeGraphIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "DQKET = DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE\n",
    "DEFAULT_NODE_SCORE = 1000.0\n",
    "GLOBAL_EXPLORE_NODE_LIMIT = 3\n",
    "REL_TEXT_LIMIT = 30\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class KGTableRetriever(BaseRetriever):\n",
    "    \"\"\"KG Table Retriever.\n",
    "\n",
    "    Arguments are shared among subclasses.\n",
    "\n",
    "    Args:\n",
    "        query_keyword_extract_template (Optional[QueryKGExtractPrompt]): A Query\n",
    "            KG Extraction\n",
    "            Prompt (see :ref:`Prompt-Templates`).\n",
    "        refine_template (Optional[BasePromptTemplate]): A Refinement Prompt\n",
    "            (see :ref:`Prompt-Templates`).\n",
    "        text_qa_template (Optional[BasePromptTemplate]): A Question Answering Prompt\n",
    "            (see :ref:`Prompt-Templates`).\n",
    "        max_keywords_per_query (int): Maximum number of keywords to extract from query.\n",
    "        num_chunks_per_query (int): Maximum number of text chunks to query.\n",
    "        include_text (bool): Use the document text source from each relevant triplet\n",
    "            during queries.\n",
    "        retriever_mode (KGRetrieverMode): Specifies whether to use keywords,\n",
    "            embeddings, or both to find relevant triplets. Should be one of \"keyword\",\n",
    "            \"embedding\", or \"hybrid\".\n",
    "        similarity_top_k (int): The number of top embeddings to use\n",
    "            (if embeddings are used).\n",
    "        graph_store_query_depth (int): The depth of the graph store query.\n",
    "        use_global_node_triplets (bool): Whether to get more keywords(entities) from\n",
    "            text chunks matched by keywords. This helps introduce more global knowledge.\n",
    "            While it's more expensive, thus to be turned off by default.\n",
    "        max_knowledge_sequence (int): The maximum number of knowledge sequence to\n",
    "            include in the response. By default, it's 30.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        index: KnowledgeGraphIndex,\n",
    "        query_keyword_extract_template: Optional[BasePromptTemplate] = None,\n",
    "        max_keywords_per_query: int = 10,\n",
    "        num_chunks_per_query: int = 10,\n",
    "        include_text: bool = True,\n",
    "        retriever_mode: Optional[KGRetrieverMode] = KGRetrieverMode.KEYWORD,\n",
    "        similarity_top_k: int = 2,\n",
    "        graph_store_query_depth: int = 2,\n",
    "        use_global_node_triplets: bool = False,\n",
    "        max_knowledge_sequence: int = REL_TEXT_LIMIT,\n",
    "        callback_manager: Optional[CallbackManager] = None,\n",
    "        object_map: Optional[dict] = None,\n",
    "        verbose: bool = False,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize params.\"\"\"\n",
    "        assert isinstance(index, KnowledgeGraphIndex)\n",
    "        self._index = index\n",
    "        self._service_context = self._index.service_context\n",
    "        self._index_struct = self._index.index_struct\n",
    "        self._docstore = self._index.docstore\n",
    "\n",
    "        self.max_keywords_per_query = max_keywords_per_query\n",
    "        self.num_chunks_per_query = num_chunks_per_query\n",
    "        self.query_keyword_extract_template = query_keyword_extract_template or DQKET\n",
    "        self.similarity_top_k = similarity_top_k\n",
    "        self._include_text = include_text\n",
    "        self._retriever_mode = KGRetrieverMode(retriever_mode)\n",
    "\n",
    "        self._graph_store = index.graph_store\n",
    "        self.graph_store_query_depth = graph_store_query_depth\n",
    "        self.use_global_node_triplets = use_global_node_triplets\n",
    "        self.max_knowledge_sequence = max_knowledge_sequence\n",
    "        self._verbose = kwargs.get(\"verbose\", False)\n",
    "        refresh_schema = kwargs.get(\"refresh_schema\", False)\n",
    "        try:\n",
    "            self._graph_schema = self._graph_store.get_schema(refresh=refresh_schema)\n",
    "        except NotImplementedError:\n",
    "            self._graph_schema = \"\"\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to get graph schema: {e}\")\n",
    "            self._graph_schema = \"\"\n",
    "        super().__init__(\n",
    "            callback_manager=callback_manager, object_map=object_map, verbose=verbose\n",
    "        )\n",
    "\n",
    "    def _get_keywords(self, query_str: str) -> List[str]:\n",
    "        \"\"\"Extract keywords.\"\"\"\n",
    "        response = self._service_context.llm.predict(\n",
    "            self.query_keyword_extract_template,\n",
    "            max_keywords=self.max_keywords_per_query,\n",
    "            question=query_str,\n",
    "        )\n",
    "        keywords = extract_keywords_given_response(\n",
    "            response, start_token=\"KEYWORDS:\", lowercase=False\n",
    "        )\n",
    "        return list(keywords)\n",
    "\n",
    "    def _extract_rel_text_keywords(self, rel_texts: List[str]) -> List[str]:\n",
    "        \"\"\"Find the keywords for given rel text triplets.\"\"\"\n",
    "        keywords = []\n",
    "        for rel_text in rel_texts:\n",
    "            keyword = rel_text.split(\",\")[0]\n",
    "            if keyword:\n",
    "                keywords.append(keyword.strip(\"(\\\"'\"))\n",
    "        return keywords\n",
    "\n",
    "    def _retrieve(\n",
    "        self,\n",
    "        query_bundle: QueryBundle,\n",
    "    ) -> List[NodeWithScore]:\n",
    "        \"\"\"Get nodes for response.\"\"\"\n",
    "        node_visited = set()\n",
    "        keywords = self._get_keywords(query_bundle.query_str)\n",
    "        if self._verbose:\n",
    "            print_text(f\"Extracted keywords: {keywords}\\n\", color=\"green\")\n",
    "        rel_texts = []\n",
    "        cur_rel_map = {}\n",
    "        chunk_indices_count: Dict[str, int] = defaultdict(int)\n",
    "        if self._retriever_mode != KGRetrieverMode.EMBEDDING:\n",
    "            for keyword in keywords:\n",
    "                keyword_nodes_map = self._index_struct.search_node_by_keyword(keyword)\n",
    "                subjs = list(keyword_nodes_map.keys())\n",
    "                node_ids = [node_id for ids in keyword_nodes_map.values() for node_id in ids]\n",
    "                for node_id in node_ids[:GLOBAL_EXPLORE_NODE_LIMIT]:\n",
    "                    if node_id in node_visited:\n",
    "                        continue\n",
    "\n",
    "                    if self._include_text:\n",
    "                        chunk_indices_count[node_id] += 1\n",
    "\n",
    "                    node_visited.add(node_id)\n",
    "                    if self.use_global_node_triplets:\n",
    "                        # Get nodes from keyword search, and add them to the subjs\n",
    "                        # set. This helps introduce more global knowledge into the\n",
    "                        # query. While it's more expensive, thus to be turned off\n",
    "                        # by default, it can be useful for some applications.\n",
    "\n",
    "                        # TODO: we should a keyword-node_id map in IndexStruct, so that\n",
    "                        # node-keywords extraction with LLM will be called only once\n",
    "                        # during indexing.\n",
    "                        extended_subjs = self._get_keywords(\n",
    "                            self._docstore.get_node(node_id).get_content(\n",
    "                                metadata_mode=MetadataMode.LLM\n",
    "                            )\n",
    "                        )\n",
    "                        subjs.update(extended_subjs)\n",
    "\n",
    "                rel_map = self._graph_store.get_rel_map(\n",
    "                    list(subjs), self.graph_store_query_depth\n",
    "                )\n",
    "                logger.debug(f\"rel_map: {rel_map}\")\n",
    "\n",
    "                if not rel_map:\n",
    "                    continue\n",
    "                rel_texts.extend(\n",
    "                    [\n",
    "                        str(rel_obj)\n",
    "                        for rel_objs in rel_map.values()\n",
    "                        for rel_obj in rel_objs\n",
    "                    ]\n",
    "                )\n",
    "                cur_rel_map.update(rel_map)\n",
    "\n",
    "        if (\n",
    "            self._retriever_mode != KGRetrieverMode.KEYWORD\n",
    "            and len(self._index_struct.embedding_dict) > 0\n",
    "        ):\n",
    "            query_embedding = self._service_context.embed_model.get_text_embedding(\n",
    "                query_bundle.query_str\n",
    "            )\n",
    "            all_rel_texts = list(self._index_struct.embedding_dict.keys())\n",
    "\n",
    "            rel_text_embeddings = [\n",
    "                self._index_struct.embedding_dict[_id] for _id in all_rel_texts\n",
    "            ]\n",
    "            similarities, top_rel_texts = get_top_k_embeddings(\n",
    "                query_embedding,\n",
    "                rel_text_embeddings,\n",
    "                similarity_top_k=self.similarity_top_k,\n",
    "                embedding_ids=all_rel_texts,\n",
    "            )\n",
    "            logger.debug(\n",
    "                f\"Found the following rel_texts+query similarites: {similarities!s}\"\n",
    "            )\n",
    "            logger.debug(f\"Found the following top_k rel_texts: {rel_texts!s}\")\n",
    "            rel_texts.extend(top_rel_texts)\n",
    "\n",
    "        elif len(self._index_struct.embedding_dict) == 0:\n",
    "            logger.warning(\n",
    "                \"Index was not constructed with embeddings, skipping embedding usage...\"\n",
    "            )\n",
    "\n",
    "        # remove any duplicates from keyword + embedding queries\n",
    "        if self._retriever_mode == KGRetrieverMode.HYBRID:\n",
    "            rel_texts = list(set(rel_texts))\n",
    "\n",
    "            # remove shorter rel_texts that are substrings of longer rel_texts\n",
    "            rel_texts.sort(key=len, reverse=True)\n",
    "            for i in range(len(rel_texts)):\n",
    "                for j in range(i + 1, len(rel_texts)):\n",
    "                    if rel_texts[j] in rel_texts[i]:\n",
    "                        rel_texts[j] = \"\"\n",
    "            rel_texts = [rel_text for rel_text in rel_texts if rel_text != \"\"]\n",
    "\n",
    "            # truncate rel_texts\n",
    "            rel_texts = rel_texts[: self.max_knowledge_sequence]\n",
    "\n",
    "        # When include_text = True just get the actual content of all the nodes\n",
    "        # (Nodes with actual keyword match, Nodes which are found from the depth search and Nodes founnd from top_k similarity)\n",
    "        if self._include_text:\n",
    "            keywords = self._extract_rel_text_keywords(\n",
    "                rel_texts\n",
    "            )  # rel_texts will have all the Triplets retrieved with respect to the Query\n",
    "            nested_node_ids = [\n",
    "                node_list\n",
    "                for keyword in keywords\n",
    "                for node_list in self._index_struct.search_node_by_keyword(keyword).values()\n",
    "            ]\n",
    "            node_ids = [_id for ids in nested_node_ids for _id in ids]\n",
    "            for node_id in node_ids:\n",
    "                chunk_indices_count[node_id] += 1\n",
    "\n",
    "        sorted_chunk_indices = sorted(\n",
    "            chunk_indices_count.keys(),\n",
    "            key=lambda x: chunk_indices_count[x],\n",
    "            reverse=True,\n",
    "        )\n",
    "        sorted_chunk_indices = sorted_chunk_indices[: self.num_chunks_per_query]\n",
    "        sorted_nodes = self._docstore.get_nodes(sorted_chunk_indices)\n",
    "\n",
    "        # TMP/TODO: also filter rel_texts as nodes until we figure out better\n",
    "        # abstraction\n",
    "        # TODO(suo): figure out what this does\n",
    "        # rel_text_nodes = [Node(text=rel_text) for rel_text in rel_texts]\n",
    "        # for node_processor in self._node_postprocessors:\n",
    "        #     rel_text_nodes = node_processor.postprocess_nodes(rel_text_nodes)\n",
    "        # rel_texts = [node.get_content() for node in rel_text_nodes]\n",
    "\n",
    "        sorted_nodes_with_scores = []\n",
    "        for chunk_idx, node in zip(sorted_chunk_indices, sorted_nodes):\n",
    "            # nodes are found with keyword mapping, give high conf to avoid cutoff\n",
    "            sorted_nodes_with_scores.append(\n",
    "                NodeWithScore(node=node, score=DEFAULT_NODE_SCORE)\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"> Querying with idx: {chunk_idx}: \"\n",
    "                f\"{truncate_text(node.get_content(), 80)}\"\n",
    "            )\n",
    "        # if no relationship is found, return the nodes found by keywords\n",
    "        if not rel_texts:\n",
    "            logger.info(\"> No relationships found, returning nodes found by keywords.\")\n",
    "            if len(sorted_nodes_with_scores) == 0:\n",
    "                logger.info(\"> No nodes found by keywords, returning empty response.\")\n",
    "                return [\n",
    "                    NodeWithScore(\n",
    "                        node=TextNode(text=\"No relationships found.\"), score=1.0\n",
    "                    )\n",
    "                ]\n",
    "            # In else case the sorted_nodes_with_scores is not empty\n",
    "            # thus returning the nodes found by keywords\n",
    "            return sorted_nodes_with_scores\n",
    "\n",
    "        # add relationships as Node\n",
    "        # TODO: make initial text customizable\n",
    "        rel_initial_text = (\n",
    "            f\"The following are knowledge sequence in max depth\"\n",
    "            f\" {self.graph_store_query_depth} \"\n",
    "            f\"in the form of directed graph like:\\n\"\n",
    "            f\"`subject -[predicate]->, object, <-[predicate_next_hop]-,\"\n",
    "            f\" object_next_hop ...`\"\n",
    "        )\n",
    "        rel_info = [rel_initial_text, *rel_texts]\n",
    "        rel_node_info = {\n",
    "            \"kg_rel_texts\": rel_texts,\n",
    "            \"kg_rel_map\": cur_rel_map,\n",
    "        }\n",
    "        if self._graph_schema != \"\":\n",
    "            rel_node_info[\"kg_schema\"] = {\"schema\": self._graph_schema}\n",
    "        rel_info_text = \"\\n\".join(\n",
    "            [\n",
    "                str(item)\n",
    "                for sublist in rel_info\n",
    "                for item in (sublist if isinstance(sublist, list) else [sublist])\n",
    "            ]\n",
    "        )\n",
    "        if self._verbose:\n",
    "            print_text(f\"KG context:\\n{rel_info_text}\\n\", color=\"blue\")\n",
    "        rel_text_node = TextNode(\n",
    "            text=rel_info_text,\n",
    "            metadata=rel_node_info,\n",
    "            excluded_embed_metadata_keys=[\"kg_rel_map\", \"kg_rel_texts\"],\n",
    "            excluded_llm_metadata_keys=[\"kg_rel_map\", \"kg_rel_texts\"],\n",
    "        )\n",
    "        # this node is constructed from rel_texts, give high confidence to avoid cutoff\n",
    "        sorted_nodes_with_scores.append(\n",
    "            NodeWithScore(node=rel_text_node, score=DEFAULT_NODE_SCORE)\n",
    "        )\n",
    "\n",
    "        return sorted_nodes_with_scores\n",
    "\n",
    "    def _get_metadata_for_response(\n",
    "        self, nodes: List[BaseNode]\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Get metadata for response.\"\"\"\n",
    "        for node in nodes:\n",
    "            if node.metadata is None or \"kg_rel_map\" not in node.metadata:\n",
    "                continue\n",
    "            return node.metadata\n",
    "        raise ValueError(\"kg_rel_map must be found in at least one Node.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
