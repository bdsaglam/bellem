schema: '2.0'
stages:
  answer-questions:
    cmd: python answer_questions.py --dataset-path bdsaglam/hotpotqa-distractor --dataset-name
      default --dataset-split validation --model llama-3-70b-tgi --temperature 0.1
      --system-prompt-filepath ../../data/raw/research-mhqa-evaluation/system-prompts/no-role.txt
      --user-prompt-template-filepath ../../data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt
      --few-shot-examples-filepath ../../data/raw/research-mhqa-evaluation/few-shot-examples/empty.json
      --out ../../data/generated/research-mhqa-evaluation/qa-results/
    deps:
    - path: ../../data/raw/research-mhqa-evaluation/few-shot-examples/empty.json
      hash: md5
      md5: d751713988987e9331980363e24189ce
      size: 2
    - path: ../../data/raw/research-mhqa-evaluation/system-prompts/no-role.txt
      hash: md5
      md5: a4ffbc2d4c7be6f3796396e6c32acb33
      size: 147
    - path: ../../data/raw/research-mhqa-evaluation/user-prompt-templates/cq.txt
      hash: md5
      md5: ac4fa9e31f4b2f7d489ceaae22dbc7ea
      size: 41
    - path: answer_questions.py
      hash: md5
      md5: 1623be97b2a06ff1b1ec8dd4635ed100
      size: 3711
    params:
      params.yaml:
        dataset.name: default
        dataset.path: bdsaglam/hotpotqa-distractor
        dataset.split: validation
        qa.few_shot_examples: empty.json
        qa.model: llama-3-70b-tgi
        qa.system_prompt: no-role.txt
        qa.temperature: 0.1
        qa.user_prompt_template: cq.txt
        run: 1
    outs:
    - path: ../../data/generated/research-mhqa-evaluation/qa-results/
      hash: md5
      md5: 36c99169be9ea53a82b27e1e7f7ba3d9.dir
      size: 19169140
      nfiles: 7406
  evaluate-answers:
    cmd: python evaluate_answers.py --dataset-path bdsaglam/hotpotqa-distractor --dataset-name
      default --dataset-split validation --qa-dir ../../data/generated/research-mhqa-evaluation/qa-results/
      --out ../../data/generated/research-mhqa-evaluation/evals/
    deps:
    - path: ../../data/generated/research-mhqa-evaluation/qa-results/
      hash: md5
      md5: 36c99169be9ea53a82b27e1e7f7ba3d9.dir
      size: 19169140
      nfiles: 7406
    - path: evaluate_answers.py
      hash: md5
      md5: c8ce61d45d52c5112b749ceee603cb4c
      size: 1940
    params:
      params.yaml:
        dataset.name: default
        dataset.path: bdsaglam/hotpotqa-distractor
        dataset.split: validation
    outs:
    - path: ../../data/generated/research-mhqa-evaluation/evals/
      hash: md5
      md5: 2d860d926aca811754e7f087766fb5c4.dir
      size: 1132309
      nfiles: 7406
  report:
    cmd: python report.py --dataset-path bdsaglam/hotpotqa-distractor --dataset-name
      default --dataset-split validation --qa-dir ../../data/generated/research-mhqa-evaluation/qa-results/
      --evals-dir ../../data/generated/research-mhqa-evaluation/evals/ --out ../../data/generated/research-mhqa-evaluation/reports/
    deps:
    - path: ../../data/generated/research-mhqa-evaluation/evals/
      hash: md5
      md5: 2d860d926aca811754e7f087766fb5c4.dir
      size: 1132309
      nfiles: 7406
    - path: ../../data/generated/research-mhqa-evaluation/qa-results/
      hash: md5
      md5: 36c99169be9ea53a82b27e1e7f7ba3d9.dir
      size: 19169140
      nfiles: 7406
    - path: report.py
      hash: md5
      md5: f5772d2cb8a64a500df38942738f5e5b
      size: 2148
    params:
      params.yaml:
        dataset.name: default
        dataset.path: bdsaglam/hotpotqa-distractor
        dataset.split: validation
    outs:
    - path: ../../data/generated/research-mhqa-evaluation/reports/results.jsonl
      hash: md5
      md5: 3f3bb891217cfec87e894fee5e91f907
      size: 18793020
    - path: ../../data/generated/research-mhqa-evaluation/reports/scores.json
      hash: md5
      md5: 22ba11428242013df30c08734a5cc279
      size: 229
